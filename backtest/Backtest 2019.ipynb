{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the backtest?\n",
    "\n",
    "The backtest analyzes data from a past period of time to determine the ideal values of seven different metrics (discussed later) for each sector.  This version of the backtest uses the jupyter notebook format to describe each part, as well as to increase efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "### Library Imports\n",
    "\n",
    "- pandas - used to manipulate data within different data structures\n",
    "- datetime - used to get today's date and current time\n",
    "- time - used for calculating runtime\n",
    "- numpy - supports mathematical functions for large volume data structures\n",
    "- product - creates a cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "import pandas as pd\n",
    "from datetime import *\n",
    "import time\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effiency and timing\n",
    "\n",
    "In the past, it has taken dozens of hours to complete the backtests.  This is costly in terms of time and electricity (which should be considered as a sustainability-oriented organization).  The block below assigns the current time to a variable so that we can later determine runtime.\n",
    "\n",
    "We also establish our sectors and metrics in lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "sectors = ['Consumer Discretionary', 'Consumer Staples', 'Energy', 'Financials', 'Health Care', 'Industrials', \\\n",
    "           'Information Technology', 'Materials', 'Real Estate', 'Telecommunication Services', 'Utilities', 'Materials']\n",
    "metrics = [ 'PE_RATIO', 'PX_TO_BOOK_RATIO', 'TRAIL_12M_EPS', 'TOT_DEBT_TO_TOT_EQY', \\\n",
    "               'PRICE_TO_FCF', 'RETURN_COM_EQY', 'RETURN_ON_ASSET' ]\n",
    "\n",
    "pd.options.mode.chained_assignment = None #allow chained assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk-free rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define risk-free rates\n",
    "TBill3Mth = (2.34/100)\n",
    "Libor3Mth = (2.62/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#   \n",
    "# Step 1: Data input and Setup, Organic Range Generation\n",
    "\n",
    "The basis of our backtest are frames - sets of each metric, each containing a different combination of values.  In order to determine what these values are, we have to come up with a range for each metric, for each sector.\n",
    "\n",
    "We also import our data file for range generation -- the last 10 years of data for each company.  The data is imported to a **dataframe**, a data structure which can be thought of as an excel sheet manipulable through python.  The dataframe is then sorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf = pd.read_excel(\"data/spyx2007-2017 dat.xlsx\", index_col=[0,1])\n",
    "#^The above code links to the .xlsx file that has QYears instead of dates;\n",
    "#I'm unsure of the status of QYear, I don't think Bob every fully implemented it.\n",
    "sdf = read_csv(\"Backtest VALUES.csv\",index_col='DATE',parse_dates=True)\n",
    "\n",
    "sdf = sdf.sort_index()\n",
    "\n",
    "#drop any rows without a date\n",
    "sdf.dropna(axis='index',how='any',inplace=True)\n",
    "\n",
    "#Define starting date to begin df with\n",
    "startDate = to_datetime('2014-03-28')\n",
    "startDate=startDate.toordinal()\n",
    "\n",
    "#Cut spyx_Sector based on DateTime range\n",
    "sdf['ordinalTime']=sdf.index\n",
    "sdf['ordinalTime'] = sdf['ordinalTime'].apply(date.toordinal)\n",
    "sdf = sdf.loc[sdf['ordinalTime']>=startDate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getRanges method\n",
    "\n",
    "The getRanges method returns a list of ranges, one for each metric, for that specific sector.  A range has a low value, high value, and step value (incrementation value).  While this code is visually unappealing, it's relatively practical. \n",
    "\n",
    "It is worth noting that we take ranges from the 25th percentile to the 75th percentile (the middle section of a normal distribution).  The companies in the top 25% for a metric may be outliers or overvalued based on that number, and the companies in the lower 25% may be underperforming.  \n",
    "\n",
    "It is also worth noting the step values.  These are generally safe bets for typical output to create a reasonable number of frames.  Remember, runtime is **_exponential_**.*\n",
    "\n",
    "_\\*Proposed change: change step-by amounts in range functions to be computer-generated\\*_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRanges(sector):\n",
    "    peRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'PE_RATIO'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf.loc[(slice(None),sector), 'PE_RATIO'].dropna(), 75))), 2)\n",
    "    pbRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'PX_TO_BOOK_RATIO'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf.loc[(slice(None),sector), 'PX_TO_BOOK_RATIO'].dropna(), 75))))\n",
    "    epsRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'TRAIL_12M_EPS'].dropna(), 25))), \\\n",
    "                      int(round(np.percentile(sdf.loc[(slice(None),sector), 'TRAIL_12M_EPS'].dropna(), 75))), 2)\n",
    "    deRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'TOT_DEBT_TO_TOT_EQY'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf.loc[(slice(None),sector), 'TOT_DEBT_TO_TOT_EQY'].dropna(), 75))), 10)\n",
    "    fcfRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'PRICE_TO_FCF'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf.loc[(slice(None),sector), 'PRICE_TO_FCF'].dropna(), 75))), 5)\n",
    "    roeRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'RETURN_COM_EQY'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf.loc[(slice(None),sector), 'RETURN_COM_EQY'].dropna(), 75))), 2)\n",
    "    roaRange =  range(int(round(np.percentile(sdf.loc[(slice(None),sector), 'RETURN_ON_ASSET'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf.loc[(slice(None),sector), 'RETURN_ON_ASSET'].dropna(), 75))), 2)\n",
    "    return [peRange, pbRange, epsRange, deRange, fcfRange, roeRange, roaRange]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "# Step 2: Frame Generation and Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create set of dates\n",
    "datesList = sorted(set(sdf.index))\n",
    "\n",
    "#Create new Output DF for portfolios for dates\n",
    "dfPort = pd.DataFrame([],index=datesList)\n",
    "dfPort['return']=None\n",
    "dfPort['beta']=None\n",
    "dfPort['tBill3Mth']=TBill3Mth\n",
    "dfPort['treynor']=None\n",
    "dfPort['peTest']=None\n",
    "dfPort['pbTest']=None\n",
    "dfPort['epsTest']=None\n",
    "dfPort['deTest']=None\n",
    "dfPort['fcfTest']=None\n",
    "dfPort['roeTest']=None\n",
    "dfPort['roaTest']=None\n",
    "dfPort['maxHSFScore']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime\n",
    "\n",
    "The following displays the total runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:01:21.227196'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "et = time.time()\n",
    "str(datetime.timedelta(seconds = et - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
