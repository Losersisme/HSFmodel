{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the backtest?\n",
    "\n",
    "The backtest analyzes data from a past period of time to determine the ideal values of seven different metrics (discussed later) for each sector.  This version of the backtest uses the jupyter notebook format to describe each part, as well as to increase efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "### Library Imports\n",
    "\n",
    "- pandas - used to manipulate data within different data structures\n",
    "- datetime - used to get today's date and current time\n",
    "- time - used for calculating runtime\n",
    "- numpy - supports mathematical functions for large volume data structures\n",
    "- product - creates a cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "import pandas as pd\n",
    "from datetime import *\n",
    "import time\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effiency and timing\n",
    "\n",
    "In the past, it has taken dozens of hours to complete the backtests.  This is costly in terms of time and electricity (which should be considered as a sustainability-oriented organization).  The block below assigns the current time to a variable so that we can later determine runtime.\n",
    "\n",
    "We also establish our sectors and metrics in lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "sectors = ['Consumer Discretionary', 'Consumer Staples', 'Energy', 'Financials', 'Health Care', 'Industrials', \\\n",
    "           'Information Technology', 'Materials', 'Real Estate', 'Telecommunication Services', 'Utilities', 'Materials']\n",
    "metrics = [ 'PE_RATIO', 'PX_TO_BOOK_RATIO', 'TRAIL_12M_EPS', 'TOT_DEBT_TO_TOT_EQY', \\\n",
    "               'PRICE_TO_FCF', 'RETURN_COM_EQY', 'RETURN_ON_ASSET' ]\n",
    "\n",
    "pd.options.mode.chained_assignment = None #allow chained assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk-free rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define risk-free rates\n",
    "TBill3Mth = (2.34/100)\n",
    "Libor3Mth = (2.62/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#   \n",
    "# Step 1: Data input and Setup, Organic Range Generation\n",
    "\n",
    "The basis of our backtest are frames - sets of each metric, each containing a different combination of values.  In order to determine what these values are, we have to come up with a range for each metric, for each sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "We first import our data file for range generation -- the last 10 years of data for each company.  The data is imported to a **dataframe**, a data structure which can be thought of as an excel sheet manipulable through python.  The dataframe is then sorted by date.\n",
    "\n",
    "The line reading \"sdf.dropna...\" drops rows where the date is empty.  We then establish a start date (generally five years prior to the test being run), and establish the date format as \"ordinal.\"  This ensures that our date formatting is compatible with that of our code.  Finally, we cut the data based on when our start date is, so that we are not using more data than is necessary and doing an excessive amount of computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = read_csv(\"Backtest VALUES 2019.csv\",index_col='DATE',parse_dates=True)\n",
    "\n",
    "sdf = sdf.sort_index()\n",
    "\n",
    "#drop any rows without a date\n",
    "sdf.dropna(axis='index',how='any',inplace=True)\n",
    "\n",
    "#Define starting date to begin df with\n",
    "startDate = to_datetime('2014-03-28')\n",
    "startDate=startDate.toordinal()\n",
    "\n",
    "#Cut spyx_Sector based on DateTime range\n",
    "sdf['ordinalTime']=sdf.index\n",
    "sdf['ordinalTime'] = sdf['ordinalTime'].apply(date.toordinal)\n",
    "sdf = sdf.loc[sdf['ordinalTime']>=startDate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getRanges method\n",
    "\n",
    "The getRanges method returns a list of ranges, one for each metric, for that specific sector.  A range has a low value, high value, and step value (incrementation value).  While this code is visually unappealing, it's relatively practical. \n",
    "\n",
    "It is worth noting that we take ranges from the 25th percentile to the 75th percentile (the middle section of a normal distribution.  If you're unsure what a normal distribution looks like and why we chose these percentages, I suggest researching these so that you have a better understanding of the statistics behind this).  The companies in the top 25% for a metric may be outliers or overvalued based on that number, and the companies in the lower 25% may be underperforming.  \n",
    "\n",
    "It is also worth noting the step values.  These are generally safe bets for typical output to create a reasonable number of frames.  Remember, runtime is **_exponential_**.*  One of our current tasks for improving the model is to develop an algorithm to calculate the step value; for example if the range starts at 20 and goes up to 120, a step of 10 has 12 potential frame values, while a step value of 5 has 24.  The fewer frame values we have, the more quickly the code will run; too large of a step value, and we may be distorting the accuracy of the backtest.\n",
    "\n",
    "First, we have to import the data again as an excel sheet.  This is due to some conflicts with \"None\" values as read by a CSV file.  We then sort the data by date and group the rows by sector.\n",
    "\n",
    "We then define a function which gets the appropriate data for each metric and returns the ranges as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the same CSV file creates issues with the slice(None) function\n",
    "sdf2 = pd.read_excel(\"Backtest VALUES 2019.xlsx\", index_col=[0,1])\n",
    "sdf2 = sdf2.sort_index()\n",
    "sdf2.groupby('GICS_SECTOR_NAME').nunique()\n",
    "\n",
    "def getRanges(sector):\n",
    "    peRange =  range(int(round(np.percentile(sdf2.loc[(slice(None), sector), 'PE_RATIO'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf2.loc[(slice(None), sector), 'PE_RATIO'].dropna(), 75))), 2)\n",
    "    pbRange =  range(int(round(np.percentile(sdf2.loc[(slice(None),sector), 'PX_TO_BOOK_RATIO'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf2.loc[(slice(None),sector), 'PX_TO_BOOK_RATIO'].dropna(), 75))))\n",
    "    epsRange =  range(int(round(np.percentile(sdf2.loc[(slice(None),sector), 'TRAIL_12M_EPS'].dropna(), 25))), \\\n",
    "                      int(round(np.percentile(sdf2.loc[(slice(None),sector), 'TRAIL_12M_EPS'].dropna(), 75))), 2)\n",
    "    deRange =  range(int(round(np.percentile(sdf2.loc[(slice(None),sector), 'TOT_DEBT_TO_TOT_EQY'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf2.loc[(slice(None),sector), 'TOT_DEBT_TO_TOT_EQY'].dropna(), 75))), 10)\n",
    "    fcfRange =  range(int(round(np.percentile(sdf2.loc[(slice(None),sector), 'PX_TO_FREE_CASH_FLOW'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf2.loc[(slice(None),sector), 'PX_TO_FREE_CASH_FLOW'].dropna(), 75))), 5)\n",
    "    roeRange =  range(int(round(np.percentile(sdf2.loc[(slice(None),sector), 'RETURN_COM_EQY'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf2.loc[(slice(None),sector), 'RETURN_COM_EQY'].dropna(), 75))), 2)\n",
    "    roaRange =  range(int(round(np.percentile(sdf2.loc[(slice(None),sector), 'RETURN_ON_ASSET'].dropna(), 25))), \\\n",
    "                     int(round(np.percentile(sdf2.loc[(slice(None),sector), 'RETURN_ON_ASSET'].dropna(), 75))), 2)\n",
    "    \n",
    "    return peRange, pbRange, epsRange, deRange, fcfRange, roeRange, roaRange;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "# Step 2: Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output functions\n",
    "\n",
    "The backtest prints out three sheets as output.\n",
    "\n",
    "SectorNameIndPortPeriodDate is a sheet showing hypothetical groupings of companies, per quarter, which fit each frame.  It gives the data for each of these companies during that quarter.  This is the largest sheet; the number of frames times the number of quarters = the number of rows in this spreadsheet. \n",
    "\n",
    "SectorNameIndPortfoliosDate takes the same data and displays it without showing each individual company in each test.  It shows the results of how each frame performed each quarter.\n",
    "\n",
    "SectorNameTotalPortfolioDate prints out the ultimate performance of each frame's average performance over time.  This is ordered by Treynor ratio, so the best frame (highest Treynor ratio) will be the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to output every indivdual portfolio inside each period\n",
    "def outputIndPeriod(df, date, sect):\n",
    "        df.to_csv(sect+\"IndPortPeriod\"+time.strftime(\"d%dm%my%Y\")+\".csv\", mode='a')\n",
    "        \n",
    "#output each portfolio with dates\n",
    "def outputIndPort(dfPort, params, sect):\n",
    "    dfPort.to_csv(sect+\"IndividualPortfolios\"+time.strftime(\"d%dm%my%Yh\")+\".csv\", \\\n",
    "                  mode='a',index_label=(\"T\"+str(params[0])+str(params[1])+str(params[2])+str(params[3])\\\n",
    "                        +str(params[4])+str(params[5])+str(params[6])))\n",
    "\n",
    "#Output total portfolio with parameters\n",
    "def outputTotalPort(dfTotalPort, params, sect):\n",
    "    dfTotalPort.to_csv(sect+\"TotalPortfolio\"+time.strftime(\"d%dm%my%Yh\")+\".csv\", mode='w',index_label=(\"T\"+\"Portfolio\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to loop through every date and output an individual portfolio\n",
    "def calculatePortLoop(dateList, params, sect):\n",
    "    for date in datesList:\n",
    "        df = spyx_Sector.loc[spyx_Sector.index==date]\n",
    "        df['peTest']=params[0]\n",
    "        df['pbTest']=params[1]\n",
    "        df['epsTest']=params[2]\n",
    "        df['deTest']=params[3]\n",
    "        df['fcfTest']=params[4]\n",
    "        df['roeTest']=params[5]\n",
    "        df['roaTest']=params[6]\n",
    "        df['peScore']=df['PE_RATIO']<params[0]\n",
    "        df['pbScore']=df['PX_TO_BOOK_RATIO']<params[1]\n",
    "        df['epsScore']=df['TRAIL_12M_EPS']>params[2]\n",
    "        df['deScore']=df['TOT_DEBT_TO_TOT_EQY']<params[3]\n",
    "        df['fcfScore']=df['PX_TO_FREE_CASH_FLOW']>params[4]\n",
    "        df['roeScore']=df['RETURN_COM_EQY']>params[5]\n",
    "        df['roaScore']=df['RETURN_ON_ASSET']>params[6]\n",
    "        df['betaScore']=1/(df['ADJUSTED_BETA']*1000)\n",
    "        df['hsfScore']=df['peScore'].astype(int)+df['pbScore'].astype(int)+df['epsScore'].astype(int)+\\\n",
    "            df['deScore'].astype(int)+df['fcfScore'].astype(int)+df['roeScore'].astype(int)+df['roaScore'].astype(int)\n",
    "        df['betaScore']\n",
    "        df['ind']=\"T\"+df['peTest'].map(str)+df['pbTest'].map(str)+df['epsTest'].map(str)+df['deTest'].map(str)+\\\n",
    "            df['fcfTest'].map(str)+df['roeTest'].map(str)+df['roaTest'].map(str)\n",
    "        df.sort_values(by='hsfScore',ascending=False,inplace=True)\n",
    "        df=df.iloc[0:5]\n",
    "        outputIndPeriod(df,date, sect)\n",
    "        dfPort.loc[dfPort.index==date,'peTest'] = df.ix[0,'peTest']\n",
    "        dfPort.loc[dfPort.index==date,'pbTest'] = df.ix[0,'pbTest']\n",
    "        dfPort.loc[dfPort.index==date,'epsTest'] = df.ix[0,'epsTest']\n",
    "        dfPort.loc[dfPort.index==date,'deTest'] = df.ix[0,'deTest']\n",
    "        dfPort.loc[dfPort.index==date,'fcfTest'] = df.ix[0,'fcfTest']\n",
    "        dfPort.loc[dfPort.index==date,'roeTest'] = df.ix[0,'roeTest']\n",
    "        dfPort.loc[dfPort.index==date,'roaTest'] = df.ix[0,'roaTest']\n",
    "        dfPort.loc[dfPort.index==date,'maxHSFScore'] = df['hsfScore'].max()\n",
    "        dfPort.loc[dfPort.index==date,'return'] = (df['RETURN'].mean())\n",
    "        dfPort.loc[dfPort.index==date,'beta'] = (df['ADJUSTED_BETA'].mean())\n",
    "    dfPort['treynor']=(dfPort['return']-TBill3Mth)/dfPort['beta']\n",
    "    dfPort['ind']=\"T\"+dfPort['peTest'].map(str)+dfPort['pbTest'].map(str)+dfPort['epsTest'].map(str)+dfPort['deTest'].map(str)+\\\n",
    "        dfPort['fcfTest'].map(str)+dfPort['roeTest'].map(str)+dfPort['roaTest'].map(str)\n",
    "    return dfPort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartesian Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(sector):\n",
    "    for params in product(peRange, pbRange, epsRange, deRange, fcfRange, roeRange, roaRange):\n",
    "        calculatePortLoop(datesList, params, sector)\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'meanReturn'] = dfPort['return'].mean()\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'meanBeta'] = dfPort['beta'].mean()\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'peTest'] = params[0]\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'pbTest'] = params[1]\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'epsTest'] = params[2]\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'deTest'] = params[3]\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'fcfTest'] = params[4]\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'roeTest'] = params[5]\n",
    "        dfTotalPort.loc[dfTotalPort['ind']==params,'roaTest'] = params[6]\n",
    "        #print(dfPort)\n",
    "        outputIndPort(dfPort,params, sector)\n",
    "    dfTotalPort['totalTreynor']=(dfTotalPort['meanReturn']-dfTotalPort['tBill3Mth'])/dfTotalPort['meanBeta']\n",
    "    dfTotalPort.sort_values('totalTreynor',ascending=False, inplace=True)\n",
    "    dfTotalPort.set_index(\"T\"+dfTotalPort['peTest'].map(str) + dfTotalPort['pbTest'].map(str) +\\\n",
    "                      dfTotalPort['epsTest'].map(str) + dfTotalPort['deTest'].map(str) +\\\n",
    "                      dfTotalPort['fcfTest'].map(str) + dfTotalPort['roeTest'].map(str) +\\\n",
    "                      dfTotalPort['roaTest'].map(str), inplace = True)\n",
    "    outputTotalPort(dfTotalPort,params, sector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "# Step 3: Naming sector, Producing Output Per Sector, Calculating Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\2rtma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "sector = 'Utilities'\n",
    "peRange, pbRange, epsRange, deRange, fcfRange, roeRange, roaRange = getRanges(sector)\n",
    "\n",
    "spyx_Sector = sdf.loc[sdf['GICS_SECTOR_NAME']==sector]\n",
    "    \n",
    "#Create set of dates\n",
    "datesList = sorted(set(sdf.index))\n",
    "\n",
    "#Create new Output DF for portfolios for dates\n",
    "dfPort = pd.DataFrame([],index=datesList)\n",
    "dfPort['return']=None\n",
    "dfPort['beta']=None\n",
    "dfPort['tBill3Mth']=TBill3Mth\n",
    "dfPort['treynor']=None\n",
    "dfPort['peTest']=None\n",
    "dfPort['pbTest']=None\n",
    "dfPort['epsTest']=None\n",
    "dfPort['deTest']=None\n",
    "dfPort['fcfTest']=None\n",
    "dfPort['roeTest']=None\n",
    "dfPort['roaTest']=None\n",
    "dfPort['maxHSFScore']=None\n",
    "\n",
    "#Create new Output DF for total portfolios\n",
    "dfTotalPort = pd.DataFrame([])\n",
    "dfTotalPort['ind']=list(product(peRange,pbRange,epsRange,deRange,fcfRange,roeRange,roaRange))\n",
    "dfTotalPort['meanReturn']=None\n",
    "dfTotalPort['meanBeta']=None\n",
    "dfTotalPort['tBill3Mth']=TBill3Mth\n",
    "dfTotalPort['totalTreynor']=None\n",
    "dfTotalPort['peTest']=None\n",
    "dfTotalPort['pbTest']=None\n",
    "dfTotalPort['epsTest']=None\n",
    "dfTotalPort['deTest']=None\n",
    "dfTotalPort['fcfTest']=None\n",
    "dfTotalPort['roeTest']=None\n",
    "dfTotalPort['roaTest']=None\n",
    "    \n",
    "prod(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime\n",
    "\n",
    "The following displays the total runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:11:12.127404'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "et = time.time()\n",
    "str(datetime.timedelta(seconds = et - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
